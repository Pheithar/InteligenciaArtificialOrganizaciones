{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLJwZEZEyzf-"
   },
   "source": [
    "# Predicción de generos de libros basados en el resumen\n",
    "\n",
    "A continaución se decribe la técnica de text mining aplicada al objetivo de conseguir predicciones lo más certeras posibles en el género de un libro. Inicialmente se trata de generar un único género. La técnica aplicada es word embedding [tutorial](https://www.tensorflow.org/tutorials/text/word_embeddings#word_embeddings_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wOxuSCzF8Yk"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9fiAaOA_aXz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D, Dropout\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Nhvsn8Qz26D"
   },
   "outputs": [],
   "source": [
    "# Variables generales del modelo\n",
    "BATCH_SIZE = 32\n",
    "VOCAB_SIZE = 12000\n",
    "SEQUENCE_LENGTH = 150\n",
    "EMBEDDING_DIM = 128\n",
    "EPOCHS = 2\n",
    "N_GRAMS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkVXREUbzoEe"
   },
   "source": [
    "## Paso 1: Carga de datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2wfjB9SCIKt"
   },
   "outputs": [],
   "source": [
    "# Se cargan los datos para la predicción de un género\n",
    "data = pd.read_csv('./datos/datos_p1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MU9DcV5YU41"
   },
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrUra9qs0Lz-"
   },
   "source": [
    "Se calcula el número de generos totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rk-ZeyJzMKHB"
   },
   "outputs": [],
   "source": [
    "genres = np.unique(data['Main Genre'])\n",
    "num_genres = len(genres)\n",
    "\n",
    "# Se muestran los 5 primeros generos\n",
    "print(\"Los 5 primeros generos son: \" + str(genres[:5]))\n",
    "print(\"Y hay un total de: \" + str(num_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnCCj5Jv04hI"
   },
   "source": [
    "Se realiza una aleatorización de los datos para evitar posibles sesgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ht55RIzUcV--"
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2c94X3q1Zfa"
   },
   "source": [
    "Se realiza una vectorización de las salidas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZzKnp0O1fzk"
   },
   "outputs": [],
   "source": [
    "label_vector = []\n",
    "for i, label in enumerate(data[\"Main Genre\"].values):\n",
    "    label_vector.append([])\n",
    "    for genre in genres:\n",
    "        if label == genre:\n",
    "            label_vector[i].append(1)\n",
    "        else:\n",
    "            label_vector[i].append(0)\n",
    "\n",
    "label_vector = np.array(label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8BOXEzP2Ms-"
   },
   "outputs": [],
   "source": [
    "label_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5n9n5cgR2scy"
   },
   "outputs": [],
   "source": [
    "label_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxxJmSyV1Byg"
   },
   "source": [
    "División de los datos en conjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l__rlGoUdEIs"
   },
   "outputs": [],
   "source": [
    "train_size = (int)(0.7*data.shape[0])\n",
    "train_X = data[\"Description\"][:train_size].values\n",
    "train_y = label_vector[:train_size]\n",
    "test_X = data[\"Description\"][train_size:].values\n",
    "test_y = label_vector[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36UP8lPHafnF"
   },
   "outputs": [],
   "source": [
    "# Se transforman los conjuntos al formato solicitado por tensorflow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_y)).batch(10)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_X, test_y)).batch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1Mo7n7p5oAM"
   },
   "source": [
    "## Paso 2: Generar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5mDC91iKMPq"
   },
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=SEQUENCE_LENGTH,\n",
    "    ngrams=N_GRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp7f5U5IKiUO"
   },
   "outputs": [],
   "source": [
    "# Determina la frecuencia de valores individuales y crea un vocabulario con ellas\n",
    "vectorize_layer.adapt(train_X)\n",
    "# Para visualizar el vocabulario: vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mhSa-GrK7_B"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  vectorize_layer,\n",
    "  Embedding(VOCAB_SIZE, EMBEDDING_DIM, name=\"embedding\"),\n",
    "  GlobalAveragePooling1D(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dropout(0.3),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dropout(0.3),\n",
    "  Dense(num_genres)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSufOyFV8hCR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87Dx8N-jAZf5"
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9vuX_un8GyX"
   },
   "outputs": [],
   "source": [
    "historic = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset, \n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtqdK5KU8r9R"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4C27fu0HSaN"
   },
   "outputs": [],
   "source": [
    "plt.plot(historic.history['categorical_accuracy'])\n",
    "plt.plot(historic.history['val_categorical_accuracy'])\n",
    "plt.title('model categorical accuracy')\n",
    "plt.ylabel('categorical accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tm890D0M_Af"
   },
   "outputs": [],
   "source": [
    "index = historic.history['val_categorical_accuracy'].index(max(historic.history['val_categorical_accuracy']))\n",
    "\n",
    "print(\"Valor entrenamiento final:\", historic.history['categorical_accuracy'][-1])\n",
    "print(\"Valor test final:\", historic.history['val_categorical_accuracy'][-1])\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Valor entrenamiento sin overfitting:\", historic.history['categorical_accuracy'][index])\n",
    "print(\"Valor test sin overfitting:\", historic.history['val_categorical_accuracy'][index])\n",
    "\n",
    "print(\"Numero de ciclos hasta overfitting:\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eT7K5KK_OouP"
   },
   "outputs": [],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmHA_ye7FfEV"
   },
   "outputs": [],
   "source": [
    "prediction_model = Sequential([model, tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KVJrMyp-nxf"
   },
   "outputs": [],
   "source": [
    "for i, j in test_dataset.take(1):\n",
    "  predicted_genre = np.argmax(prediction_model.predict(i)[3])\n",
    "  print(genres[predicted_genre])\n",
    "  print(genres[np.argmax(j[3])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQHxrWN4G04P"
   },
   "source": [
    "Caso de uso\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlgW2xA2FLVd"
   },
   "outputs": [],
   "source": [
    "prediction = prediction_model.predict([\"The Kingkiller Chronicle takes place in the fictional world of Temerant, a large continent of which the known part, called the Four Corners of Civilization, is divided into several distinct nations and cultures. Much of the world follows a religion similar, though not identical, to medieval Christianity. Coexisting alongside the mortal world is the realm of The Fae, a parallel universe inhabited by supernatural creatures which can move between the two realms only when the moon is full. Magic exists in Temerant, too, but obeys a well-defined set of rules and principles that can only be exploited by those who have trained in its professional and scientific use.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WYcy6ViFSi1"
   },
   "outputs": [],
   "source": [
    "predicted_genre = np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNbjFDH7FXR7"
   },
   "outputs": [],
   "source": [
    "print(genres[predicted_genre])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CO9ljTrG7zc"
   },
   "source": [
    "Real: fantasía, aventura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixgOz-LVFvsf"
   },
   "outputs": [],
   "source": [
    "prediction = prediction_model.predict([\"Our species, Homo sapiens, started out as just another, biologically insignificant, animal among countless others, but at some point made a very quick “jump” to domination over other species that has left man anxious, destructive, and often miserable despite all our efforts to be happy. Yuval Noah Harari’s book, ‘Sapiens,’ traces the origins, mechanisms, and effects of what we think of as “human progress” from small bands of hunter gatherers 100,000 years ago to the present-day global network through which our species has come to dominate the entire Earth. This bird’s-eye view of human history delves into the development of sapiens’ social organization and the structural features of human cultures through which our species has spread, replicated, and evolved, including the breakthroughs of human language with its infinite expressions, the use of the human imagination, and the rise of the concept of a better future that lies just beyond the horizon. Through these mechanisms, our species has evolved socially, rather than biologically, into a species that’s increasingly in control of our own destiny. This book considers not only how this evolution has occurred but questions of whether this “progress” has truly been beneficial and how we might, with our awareness of how we got here, decide where we want to go.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfbo2Te5F17V"
   },
   "outputs": [],
   "source": [
    "predicted_genre = np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOHO2l0KF3NY"
   },
   "outputs": [],
   "source": [
    "print(genres[predicted_genre])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ym5B-yobqHg"
   },
   "source": [
    "Real: historia, ciencia, filosofía"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Embedded_1_Genre.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
